# Today I Learned



* EC2 인스턴스를 이용한 서버 인스턴스 생성과 관리 (p13~25)
* 소스코드 배포 (p25 ~ 42)
* 하나의 서버에서 두 개의 애플리케이션 서비스 (P41)
* Auto Scaling 그룹 생성 (p48)
* Auto Scaling 그룹, 대상 그룹, 로드 밸러스 구성 (P65)
* 장애 조치 아키텍처 구성 (P73)

---



### 교재 13~25페이지 EC2 인스턴스 생성 실습

**nvm(노드 버전 관리자: Node Version Manager) 설치**

```bash
[ec2-user@ip-172-31-38-230 ~]$ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.11/install.sh | bash

[ec2-user@ip-172-31-38-230 ~]$ . ~/.nvm/nvm.sh
[ec2-user@ip-172-31-34-78 .nvm]$ nvm install 10.13.0
# -e 옵션은 실행하는 옵션 
[ec2-user@ip-172-31-34-78 .nvm]$ node -e "console.log('Running Node.js' + process.version)"
`Running Node.jsv10.13.0
```

* 앞에 점:  ⇐ source 의미 (환경변수를 바꿀 때 사용)
  * $ source ~/.nvm/nvm.sh 동일

* .nvm/ ⇐ Hidden 파일/디렉터리

---



### 25 ~ 42페이지 소스코드 배포

* git 설치에 필요한 패키지 다운로드

```bash
[ec2-user@ip-172-31-38-230 ~]$ sudo yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel

[ec2-user@ip-172-31-38-230 ~]$ cd /var
[ec2-user@ip-172-31-38-230 var]$ sudo mkdir www
[ec2-user@ip-172-31-38-230 var]$ sudo chown ec2-user www

[ec2-user@ip-172-31-34-78 www]$ git clone https://github.com/deopard/aws-exercise-a.git
[ec2-user@ip-172-31-38-230 www]$ cd aws-exercise-a/

[ec2-user@ip-172-31-42-0 aws-exercise-a]$ sudo yum install -y tree
[ec2-user@ip-172-31-38-230 aws-exercise-a]$ tree .

# npm 패키지 설치
[ec2-user@ip-172-31-38-230 aws-exercise-a]$ npm install
`added 50 packages from 47 contributors and audited 50 packages in 1.599s
```

* 서버사이드 스크립트 언어
  * JSP, ASP, PHP 같은 동적 언어
* 웹 애플리케이션 서버 부담으로 인해 **다중화** 및 웹 서버를 이용해 **로드 밸런싱**이용

```bash
# 웹 서버와 웹 애플리케이션 서버로 이원화 
# 웹 서버 => nginx
# 웹 애플리케이션 서버 => Phusion Passenger

[ec2-user@ip-172-31-38-230 www]$ wget https://s3.amazonaws.com/phusion-passenger/releases/passenger-5.3.6.tar.gz

[ec2-user@ip-172-31-38-230 www]$ sudo mkdir /var/passenger
[ec2-user@ip-172-31-38-230 www]$ sudo chown ec2-user /var/passenger/
# 압축풀기
[ec2-user@ip-172-31-38-230 www]$ tar -xzvf passenger-5.3.6.tar.gz -C /var/passenger/
```

* https://rvm.io/rvm/install 페이지에서 GPG 키 복사

```bash
[ec2-user@ip-172-31-38-230 www]$ gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB

[ec2-user@ip-172-31-38-230 www]$ curl -sSL https://get.rvm.io | bash -s stable

[ec2-user@ip-172-31-34-78 www]$ . ~/.rvm/scripts/rvm
[ec2-user@ip-172-31-34-78 www]$ rvm reload
# rvm에 필요한 패키지 다운로드
[ec2-user@ip-172-31-34-78 www]$ rvm requirements run
[ec2-user@ip-172-31-34-78 www]$ rvm install 2.4.3
```

* Passenger 명령어 환경변수 추가

```bash
# passenger 환경변수 추가
[ec2-user@ip-172-31-38-230 www]$ echo export PATH=/var/passenger/passenger-5.3.6/bin:$PATH >> ~/.bash_profile
[ec2-user@ip-172-31-38-230 www]$ source ~/.bash_profile

[ec2-user@ip-172-31-38-230 www]$ passenger-install-nginx-module
```

* 가상 메모리 오류 발생

```bash
[ec2-user@ip-172-31-38-230 www]$ sudo dd if=/dev/zero of=/swap bs=1M count=1024
[ec2-user@ip-172-31-38-230 www]$ sudo mkswap /swap
[ec2-user@ip-172-31-38-230 www]$ sudo swapon /swap
[ec2-user@ip-172-31-38-230 www]$ passenger-install-nginx-module
```

* 권한 오류 발생

```bash
[ec2-user@ip-172-31-38-230 www]$ export ORIG_PATH="$PATH"
[ec2-user@ip-172-31-38-230 www]$ rvmsudo -E /bin/bash
[root@ip-172-31-38-230 www]# export PATH="$ORIG_PATH"
[root@ip-172-31-38-230 www]# export rvmsudo_secure_path=1
[root@ip-172-31-38-230 www]# /home/ec2-user/.rvm/gems/ruby-2.4.3/wrappers/ruby /var/passenger/passenger-5.3.6/bin/passenger-install-nginx-module

# 설치 완료 후
[root@ip-172-31-36-12 aws-exercise-a]# exit
```

* nginx 설정 변경

```bash
[ec2-user@ip-172-31-36-12 aws-exercise-a]$ sudo vi /opt/nginx/conf/nginx.conf

worker_processes  1;

events {
    worker_connections 1024;
}


http {
    server_names_hash_bucket_size 256;
    passenger_root /var/passenger/passenger-5.3.6;
    passenger_ruby /home/ec2-user/.rvm/gems/ruby-2.4.3/wrappers/ruby;

    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    server {
        listen                 80;
        # 서버의 이름을 나타냄, 클라이언트에서 어떤 주소로 요청을 보냈을 때,
        # nginx가 그 주소와 정의돼 있는 server_name을 보고 어떤 server에게 요청을 보내줄지 결정
        server_name            15.164.163.12;
        root                   /var/www/aws-exercise-a/public;
        # Passenger 앱 명시
        passenger_enabled      on;
        # Passenger에게 Node.js 앱임을 알려줌
        passenger_app_type     node;
        # Passenger 시작 파일
        passenger_startup_file /var/www/aws-exercise-a/app.js;
    }
}

# root 권한으로 서비스 시작
[ec2-user@ip-172-31-36-12 conf]$ sudo /opt/nginx/sbin/nginx

# nginx 구동 ⇒ $ sudo /opt/nginx/sbin/nginx
# nginx 중지 ⇒ $ sudo /opt/nginx/sbin/nginx -s stop
# nginx 재실행 ⇒ $ sudo /opt/nginx/sbin/nginx -s reload
```

* 서비스에 명령어 등록

```bash
[ec2-user@ip-172-31-36-12 aws-exercise-a]$ cd /etc/init.d
[ec2-user@ip-172-31-36-12 init.d]$ sudo vi nginx

#!/bin/sh
#
# nginx - this script starts and stops the nginx daemin
#
# chkconfig:   - 85 15 
# description:  Nginx is an HTTP(S) server, HTTP(S) reverse \
#               proxy and IMAP/POP3 proxy server
# processname: nginx
# config:      /opt/nginx/conf/nginx.conf
# pidfile:     /opt/nginx/logs/nginx.pid
# modified from http://articles.slicehost.com/2009/2/2/centos-adding-an-nginx-init-script

# Source function library.
. /etc/rc.d/init.d/functions

# Source networking configuration.
. /etc/sysconfig/network

# Check that networking is up.
[ "$NETWORKING" = "no" ] && exit 0

nginx="/opt/nginx/sbin/nginx"
prog=$(basename $nginx)

NGINX_CONF_FILE="/opt/nginx/conf/nginx.conf"

lockfile=/var/lock/subsys/nginx

start() {
    [ -x $nginx ] || exit 5
    [ -f $NGINX_CONF_FILE ] || exit 6
    echo -n $"Starting $prog: "
    daemon $nginx -c $NGINX_CONF_FILE
    retval=$?
    echo
    [ $retval -eq 0 ] && touch $lockfile
    return $retval
}

stop() {
    echo -n $"Stopping $prog: "
    killproc $prog -QUIT
    retval=$?
    echo
    [ $retval -eq 0 ] && rm -f $lockfile
    return $retval
}

restart() {
    configtest || return $?
    stop
    start
}

reload() {
    configtest || return $?
    echo -n $"Reloading $prog: "
    killproc $nginx -HUP
    RETVAL=$?
    echo
}

force_reload() {
    restart
}

configtest() {
  $nginx -t -c $NGINX_CONF_FILE
}

rh_status() {
    status $prog
}

rh_status_q() {
    rh_status >/dev/null 2>&1
}

case "$1" in
    start)
        rh_status_q && exit 0
        $1
        ;;
    stop)
        rh_status_q || exit 0
        $1
        ;;
    restart|configtest)
        $1
        ;;
    reload)
        rh_status_q || exit 7
        $1
        ;;
    force-reload)
        force_reload
        ;;
    status)
        rh_status
        ;;
    condrestart|try-restart)
        rh_status_q || exit 0
            ;;
    *)
        echo $"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}"
        exit 2
esac
```

---



### P41 하나의 서버에서 두 개의 애플리케이션 서비스

```bash
[ec2-user@ip-172-31-36-12 init.d]$ cd /var/www
[ec2-user@ip-172-31-36-12 www]$ git clone https://github.com/deopard/aws-exercise-b.git
[ec2-user@ip-172-31-36-12 www]$ cd aws-exercise-b
[ec2-user@ip-172-31-36-12 aws-exercise-b]$ tree .

ec2-user@ip-172-31-36-12 aws-exercise-b]$ npm install

[ec2-user@ip-172-31-36-12 aws-exercise-b]$ cat app.js
const express = require('express');
const app = express();

app.get('/', (req, res) => {
  res.send('AWS exercise의 B project입니다.');
});
```

* nginx 설정 변경

```bash
worker_processes  1;

events {
    worker_connections 1024;
}


http {
    server_names_hash_bucket_size 256;
    passenger_root /var/passenger/passenger-5.3.6;
    passenger_ruby /home/ec2-user/.rvm/gems/ruby-2.4.3/wrappers/ruby;

    include       mime.types;
    default_type  application/octet-stream;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    server {
        listen                 80;
        server_name            15.164.163.12;
        root                   /var/www/aws-exercise-a/public;
        passenger_enabled      on;
        passenger_app_type     node;
        passenger_startup_file /var/www/aws-exercise-a/app.js;
    }
    server {
        listen                 80;
        server_name            ec2-15-164-163-12.ap-northeast-2.compute.amazonaws.com;
        root                   /var/www/aws-exercise-b/public;
        passenger_enabled      on;
        passenger_app_type     node;
        passenger_startup_file /var/www/aws-exercise-b/app.js;
    }
}

[ec2-user@ip-172-31-36-12 aws-exercise-b]$ sudo service nginx restart
```

---



### p48 Auto Scaling 그룹 생성

* **시작 템플릿**이라는 설정 파일에 설정을 저장 후 **Auto Scaling 그룹**은 설정 템플릿에 있는 내용을 그대로 가져다 쓰는 것
* Auto Scaling을 통해 **자원 사용량에 대한 조정**도 기준 값만 정해주면 자동화 하도록 설정

1. 인스턴스 중지
2. 스냅샷 생성
3. 시작 템플릿 생성
   * Auto Scaling 그룹에게 우리 대신 인스턴스를 생성할 때 어떤 환경설정으로 생성할지를 미리 정의해두는 것
4. 시작 템플릿 생성 후 Auto Scaling 그룹 생성하기 - 서브넷으로 네트워크 망 설정
5. 자동으로 인스턴스 수를 조절하기 위한 조정 정책 설정
6. 인스턴스를 구분하기 위한 태그 값 설정

Auto Scaling의 자세한 정보 **p57**

7. Auto Scaling을 통한 인스턴스 자동 추가, 제거

```bash
$ sudo yum install stress -y

$ stress --cpu 1 --timeout 600
# 10분이나 하는 이유는 현재 인스턴스의 사용량 지표를 5분에 한번씩만 모니터링 서버로 전송하고 있기 때문
# 인스턴스를 생성할 때 '세부 모니터링 활성화' 옵션을 활성화하면 1분마다 지표를 보냄
```

---



### P65 Auto Scaling 그룹, 대상 그룹, 로드 밸런스 구성

* 대상 그룹(Target Group)
  * 로드 밸런서가 요청을 전달할 서버들을 묶어둔 개념적인 그룹
  * **로드 밸런서가 요청을 보낼 인스턴스들을 더 쉽게 관리하기 위해 만든 기능**
  * 로드 밸런서에 직접 인스턴스나 Auto Scaling 그룹을 등록하지 않고 **대상 그룹**이라는 개념을 중간에 두는 이유는 **하나의 로드 밸런서에 여러 대상 그룹들을 연결할 수 있기 때문**
    * ex) 각 인스턴스 or Auto Scaling Group에 대한 포트 지정
  * 상태 검사 항목
    * 경로: 인스턴스가 정상인지 확인하기 위해 호출할 URL 주소
    * 정상 임계값: 연속으로 **몇 번 정상 응답**을 해야만 정상 상태로 볼 것인지 지정하는 항목
    * 비정상 임계값: 연속으로 **몇 번 비정상 응답**을 해야만 정상 상태로 볼 것인지 지정하는 항목
    * 제한 시간: 타임아웃 시간으로 응답이 **몇 초** 이내로 오지 않을 경우 에러 처리
    * 간격: **몇 초** 간격으로 인스턴스의 **상태 확인**할지 지정하는 항목
* 로드 밸런서
  * 로드 밸런서는 관리하는 서버 중 **정상적으로 동작하고 있는 서버에만 요청**을 전달해줌
  * 정상적으로 동작하고 있는지 확인하기 위해 **상태 검사(Health Check) 과정**을 거치게 됨
    * 주기적으로 요청을 보내고, 요청에 응답하지 않거나 http 정상 상태 코드(200)이 아닌 다른 상태 코드를 보내온다면 **정상 상태로 변경될 때까지 클라이언트의 요청을 받지 않음** 

---



### P73 장애 조치 아키텍처 구성

* 장애 조치란 **장애 극복 기능**으로 시스템의 일부 서버에 장애가 발생했을 때 **전체 시스템이 죽는 것이 아니라 예비 시스템이 즉시 요청을 대신 처리해서 다운 타임을 최소화**한 후 문제 없이 서비스가 돌아가게 하는 것

  

#### [실습] Auto Scaling 그룹을 이용한 장애 조치

* 장애가 발생한 서버 인스턴스가 발생한다면 **해당 인스턴스가 정상 상태로 돌아올 때까지 클라이언트의 요청을 받지 않음**

* 대상 그룹 임계 값 변경 - 장애 조치가 일어나는 것을 빠르게 확인하기 위해 이와 같이 시간을 짧게 조정

```bash
정상 임계 값: 2
비정상 임계 값: 2
제한 시간: 2
간격: 5
성공 코드: 200
```

* Auto Scaling 그룹 목표 용량과 최소 용량 *2*로 설정
* nginx 접속 로그 확인

```bash
# nginx의 로그가 저장되는 경로로 이동한다.
$ cd /opt/nginx/logs

# access.log에 새로운 내용이 쌓이면 실시간으로 보여준다.
$ tail -f access.log
```

* 장애 상황 재현을 위해 하나의 서버 nginx 중지

```bash
$ sudo service nginx stop
```

* 로드 밸런서가 상태 확인(health check)를 통해 **하나의 인스턴스를 비정상 상태로 판단하기까지는** 요청 중 절반은 성공하고 절반은 에러가 발생



#### 요약

* Auto Scaling 그룹과 Elastic Load Balncer를 이용해 다중 서버 환경을 구성하는 방법을 구현
* 로드 밸런서라는 레이어를 서버 앞에 둠으로써 **스케일 아웃 가능**
  * 스케일 업: 서버의 성능 자체를 올림
  * 스케일 아웃: 서버의 대수를 늘려 처리 능력을 향상
* Auto Scaling 그룹이라는 AWS 서비스를 이용해 실시간 요청량에 따라 유연하게 서버 수를 관리